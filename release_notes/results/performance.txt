25f4ba7c1b  # Improve compare kernel (#29743)
d5c136097a  # improve .view() performance (#30554)
1b5ce05924  # don't use size()/stride() functions in TensorImpl, use size_[d]/stride_[d] instead (#30452)
289e9a07fd  # Move Tanh backward to Aten(CPU+CUDA) (#30224)
f874230d33  # Vectorize smooth L1 loss backward function on CPU. (#30046)
82c3f4861f  # Move hardtanh activation to Aten(CPU, CUDA) (#30152)
44ff7b08d8  # Reduce intrusive_ptr incref/decref costs (#30709)
8d35b6cec7  # embedding_bag make_bag_size optimization (#30701)
daef363b15  # Move Softshrink activation to Aten(CPU+CUDA) (#30229)
d6d6075573  # Optimize LayerNorm with explicit vectorization using Vec256 (#29104)
066e3ed953  # Re-apply "[bert/RoBERTa] Optimize LayerNorm with explicit vectorization using Vec256" (#31127)
60ec53c7fd  # Fix copy kernel speed regression introduced in #29631 (#31279)
7cf8b9bada  # Move leaky_relu to Aten(CPU, CUDA) (#29899)
5e8bac24b4  # Migrate soft_margin_loss from the TH to Aten (CUDA+CPU) (#28135)
489dd6cb90  # Add TORCH_DCHECK macro that checks only in debug builds (#31240)
8f3c0d541e  # Speed up `Tensor::has_names` for unnamed tensors (#31436)
79e30ff3f8  # optimize index_select performance on CPU with TensorIterator (#30598)
34561dadcd  # Don't handle bias inside cudnn_convolution* (#31524)
eb23171bce  # TensorIterator norm update (#31903)
e74a215ade  # Changed clip_grad_norm_ total_norm calculation (#32020)
7b7390778c  # Make an assert on a hotpath trigger only in DEBUG mode. (#32117)
5bc44fb6ea  # TensorIterator unrolling and vectorized load - step 0, 1 (#31974)
cc2d5b15ad  # F.normalize uses clamp_min_ inplace (#32360)
6412ca3ce9  # duplicate symbols with AT_PARALLEL_OPENMP=0 (#32568)
2471ddc96c  # Improved speed of frobenous norm for non-complex dtype (#30871)
3ee6673e99  # Refreshing numel on a stride update is pointless. (#32116)
a9583c1f75  # Vectorize softplus and its backward function on CPU (#32944)
9857d9b4cd  # fix gather regression by not materializing loop vars in the error mesâ€¦ (#33108)
31370949be  # Add zero_mask function for vectorized functions. (#32985)
7b50e76255  # optimize cat performance on CPU with TensorIterator (#30806)
