584be86c3f  # Try exporting ONNX with force_outplace=False (#29466)
06db5ad707  # Provide names for operator nodes in ONNX exported graph. (#27342)
2599b9b551  # Add output_size argument to caffe2 Int8ResizeNearest (#30202)
0febff36ac  # Export dynamic unbind/split and __getitem__ (#29136)
512c2a2df5  # Enable constant folding (#29834)
1e8ed021c6  # Support logsoftmax with dim != -1 (#30433)
968c0d4a46  # Add support for converting quantized AvgPool2d and Reshape operations (#30490)
e7fe64f6a6  # Fix typos (#30606)
4d30415f12  # Add ONNX Scripting Conv Support (#30618)
980aead1f8  # Add support for quantized slice conversion (#30498)
a51c5f5cbf  # Add JIT pass to insert permutes for conv ops (#30679)
62b10721fb  # Actually make flake8 do something (#30892)
63f1b780ba  # Support exporting aten::copy_ and aten::index_put to ONNX opset 11 (#26941)
5205556782  # Export custom ops (#29752)
e42af97349  # Add quantized concat conversion (#30887)
8013ffd400  # Fix weight_norm export for dim=0 (#31015)
79c27ba4ef  # Add ONNX Export Support to floor_divide (#31081)
97c1e90f46  # ONNX Interpolate Add Scales Params (#28324)
6ab2d1b1a4  # Partially support tensor lists in loop/concat/stack (#30126)
1d5af9599d  # Update ONNX Flatten to accept negative indices in opset 11 (#30751)
0e548a76eb  # Upgrade exported ONNX IR version to 6 (#31025)
0b57b383b1  # Im2col export (#30972)
c4f10e0fe7  # Renaming scales parameter for interpolate (#31526)
5be8dac329  # Remove non-ascii character from torch/onnx/symbolic_opset11.py
a472f0201f  # Added support for Dim operation in ONNX export (#31928)
3363ca20a7  # example_outputs Doc Edit (#31826)
4460a86cd6  # Support op registration if name starts with underscore (_) (#32017)
ffc8e255c4  # Sort export w/ negative axes (#31971)
8b4c695e47  # Added cons folding for ONNX mul, div, sqrt ops (#32077)
f326045b37  # Fix typos, via a Levenshtein-type corrector (#31523)
3ada2e0d64  # [pytorch][embeddingbag] Parallelize the EmbeddingBag operator (#4049)
43d31ae4c3  # Added ONNX model checker to ONNX export (#32298)
55c382e62b  # Fixed access to element in size tensor for scripting (#32652)
10183061eb  # [ONNX] Update ONNX landing page since 1.3 (#32805)
e03e4f3a2d  # [ONNX] Add einsum export (#32716)
1c42b9466b  # [ONNX] Update support of exporting bool type index mask (#32445)
5c019fede3  # [ONNX] Fix for constant folding flaky tests (#32546)
58e8d5588a  # [ONNX] Export bitwise_not for bool (logical_not) (#28439)
4502d8c391  # Interpolate Float [] support in ONNX (#32554)
e54d954572  # [ONNX] Add flag to enable script tests (#32654)
432858c960  # [ONNX] Fix exporting copy_ with index as tensor input (#32801)
afa8cbf8c2  # Modifed randNLike for scripting (#32830)
d678093907  # [ONNX] Extend op registration to next opsets (#32943)
868db903ae  # ONNX support for torch.take (#33061)
17d4ef9e9e  # Support using scalar tensor for split (#32493)
6249d7302b  # [ONNX] Fix export for avg_pool with default stride (#33017)
44723a1c24  # [ONNX] Fix ONNX CI (#33200)
f9ad5528e0  # Fix for rand_like as well. (#33095)
40246fa63c  # Gradient scaling API (#26512)
642bd51043  # [ONNX] Skip problematic ONNX test to unblock CI (#33323)
9823662b43  # [ONNX] Export split with list of sizes (#33161)
96989a2a11  # [ONNX] Adding ONNX large model export support in exporter (#33062)
bf0951d937  # Updating ONNX checker logic. (#33522)
a6a72ac68f  # Fix all occurrences of C416. (#33429)
15ba902c08  # Turn ONNX_ML into a proper build option. (#33424)
a0e90e1b45  # ONNX Error Message on Missing Op (#33593)
150e025be8  # [jit] stop printing crap in test_jit (#33779)
bd7e9c490a  # [jit] stop printing crap in test_jit (#33917)
8216d9ae64  # ONNX Export Support for NLLLoss (#33509)
beb4309406  # [ONNX] Reduce ONNX test time on CI (#33242)
d2b5eb2a45  # [ONNX] Fix for random generators export (#33789)
bcfd348858  # [ONNX] Export new_zeros (#34077)
3671036ef3  # Adds true_divide function, analogous to Python 's, JAX's, NumPy's (true) division (#34236)
4f62cbe7de  # [ONNX] Support one_hot (#34454)
2cf576e9ea  # small typos (#34589)
af28915164  # [quant][onnx] Add support to convert max_pool2d quantized pytorch op to C2 (#33945)
8a395882ce  # [quant][onnx] Support conversion of quantized sigmoid operator from pytorch to caffe2 (#34629)
480d1849b0  # [ONNX] Fix for expand -1 dim value (#34069)
