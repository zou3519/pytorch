3301794855  # Port ELU activation to Aten (#29275)
a02a5129a8  # Move rrelu to Aten(CPU) (#31094)
4f9d2f74e2  # Port softplus activation to Aten(CPU+CUDA) (#30504)
9ba6a768de  # Add op bitwise_or (#31559)
9a3cb1e859  # Move cauchy to Aten(CPU) (#31824)
5a76335aaa  # Move lshift to Aten (#31566)
99b3f9cac4  # Move log_sigmoid to Aten(CPU) (#30958)
e59e5ba5a3  # Move geometric to Aten(CPU) (#31878)
8098ae455c  # Move rshift to Aten (#31594)
61ee8c972f  # porting scatter_add to ATen (CPU) (#31662)
64de93d8e7  # Move log_normal to Aten(CPU) (#31854)
1c017f0c14  # Migrate max and min (binary) from TH to ATen. (#30851)
d2f66083c5  # porting gather to ATen using TensorIterator with multithreading support. (#32425)
18aab32959  # Move exponential_ from TH to Aten (CPU) (#32501)
8cb05e72c6  # Port BCELoss to ATen to increase accuracy (#31365)
9c2ed2574a  # Vectorized memory access in TensorIterator GPU loop for 1d contiguous case (#32383)
b00345a6f2  # Move normal distribution to Aten(CPU) (#32031)
330d051bd5  # [pytorch] Migrating index_add cuda to ATen (#30573)
367488b001  # Move where cuda implementation to TensorIterator (#32984)
b9a5353fee  # Move where cuda implementation to TensorIterator (#33228)
2e9b7c5fe1  # Migrate dist from TH to ATen(CPU, CUDA) (#29714)
7ae1e023e7  # glu: port cpu forward implementation to ATen (#26410)
602ef0d9d0  # [WIP] migrate scatter_ to ATen CPU (+multithreading, nondeterministic) (#33139)
d971007c29  # Migrate `random_` from the TH to Aten (CPU) (#32534)
b10a39bb32  # Migrate _cat from TH to ATen (CUDA) (#33237)
4d203c6fc8  # Move cumprod and cumsum to Aten(CPU) (#33280)
2eb95d8f4a  # Migrate `fmod` and `fmod_` from TH to ATen (CPU) (#33592)
cd0acf4374  # port masked_fill from TH to ATen (#33330)
095de1e872  # Migrate `random_` from the TH to Aten (CPU and CUDA) (#33663)
87b3f87f27  # Migrate prelu from CUDA_tensor_apply2 to TensorIterator (#34003)
77b9016a8e  # Migrate gamma grad from CUDA_tensor_apply3 to TensorIterator (#34020)
ff1fc402a8  # Migrate dirichlet from CUDA_tensor_apply3 to TensorIterator (#34021)
3def76583a  # [RESUBMIT] [pytorch] Migrating index_add cuda to ATen (#33548)
4074d559e4  # Migrate kl_div_backward from CUDA_tensor_apply3 to TensorIterator (#34022)
5082839de5  # Migrate Lerp from CUDA_tensor_apply4 to TensorIterator (#33994)
27f56632a4  # Migrate bce loss from CUDA_tensor_apply3 to TensorIterator (#34023)
1affaf8d10  # Migrate lerp from CUDA_tensor_apply3 to TensorIterator (#34025)
57c1b80ec2  # [pytorch]Migrate _th_ger to Aten and kill resize_scalar in codegen (#33792)
fbbeee0983  # Port `remainder` from TH to ATen (CPU and CUDA) (#34136)
7848c229b8  # Move min and max(reduce all) to Aten(CPU) (#33936)
c3c0cf1591  # Migrate binary_cross_entropy_backward from CUDA_tensor_apply4 to (#33995)
a66b837b19  # Migrate dirichlet_grad from CUDA_tensor_apply4 to TensorIterator (#33996)
b678256bfb  # Move glu to Aten(CPU) (#33179)
