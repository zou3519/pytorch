a074080d57  # Mark `c10d::~NCCLUtils` as noexcept (#29118)
183aa1534f  # Add --no_python flag (#29144)
1d3f3a1a0c  # Add pybind11 trampoline class for c10d.Store (#30415)
0282c5ae69  # Add helper to aggregate multiple process groups (#25768)
f531815526  # Deprecate tensor.type() (#30281)
619e2ffe23  # Replace deprecated AT_* with TORCH_* to reduce warnings in c10d
5c56986738  # Attach autograd edges only for tensors requiring grad. (#30904)
776fdda753  # Add debug info API for distributed autograd. (#30642)
4f342a61c1  # add the worker IDs outside of addSendRpcBackward to ensure they are (#30914)
06c7420fa2  # Raise error if a block can not be found from a CUDA tensor (#30870)
b01b05790e  # Fix memory leak due to circular dependency. (#31030)
a9ad98fb25  # Remove unused argument "destId" in addSendRpcBackward (#31207)
70013415c7  # DDP should not set grad for globally unused params (#28883)
c5d3be1102  # Remove the second copy on calling dist_autograd_context._known_worker_ids() (#31206)
fde94e7556  # Provide async mode for local autograd engine. (#31230)
20e5c90d82  # accept url query when rank or wolrd_size is specified (#32016)
