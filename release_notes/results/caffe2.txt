0c18de2623  # Add inferBoundShapeOp
6c9b188262  # Support in-place update in IndexHashOp (#30275)
ee20e66c48  # replace the SLSRQ for their right emulations in the replayer test (#30367)
45880f4246  # Change logging to remove the word "error" from info log
d32f261f16  # make the order btw div and mul in adagrad update consistent (#30449)
ca072951d5  # move MaskedAdagrad to caffe2/operators/experimental/optimizers (#30714)
e09c415387  # Back out "make the order btw div and mul in adagrad update consistent" (#30737)
6848f9abb8  # call fp16<->fp32 routines in fbgemm from Half2Float and Float2Half operators (#30715)
42324cb6e8  # Change interface from map of TensorShape to shapeInfoMap (#30802)
c34ef1aa2e  # Automatic update of fbcode/onnx to c08a7b76cf7c1555ae37186f12be4d62b2c39b3b (#30619)
a42d093db2  # FCTransposed to FbFCPacked (#29766)
bb7befb12c  # Support loading by blob in predictor
313c211f3f  # Calling JITed 8 Bit Fused SLS in FBGEMM from C2 (#30926)
7f5f2e8871  # add ZERO_COLLISION_HASH to caffe2 data type (#30912)
4a751dfc20  # optimize MulGradient for common shapes (#19705)
199e1fb348  # Use AVX2 to increase frequency for FP16<->FP32 Caffe2 ops (#31203)
52b8a52e4d  # move AliasWithNameOp to caffe2/operators
d9c3913dfc  # move BatchPermutationOp to caffe2/operators
b0bd35ff13  # caffe2/event: allow multiple errors such as when cancelled (#31335)
d08250c223  # fix zero-batch handling in convtranspose (#24341)
4c341582ea  # modify model to enable loading by blob (#31507)
2099cfa13d  # Fix input_channels divisibility check in concat_split_op (#31448)
7a12ccd003  # optimize FloatToFused8BitRowwiseQuantized and Fused8BitRowwiseQuantizedToFloat (#31470)
a54dc87e8e  # revert D18805532 and make numerics of masked adagrad consistent with unmasked adagrad (#30784)
39508501a4  # Create byte-aware word lstm benchmark (#31260)
4983ef8de1  # Integrating MaskedAdagrad
b522a8e1ff  # Optimize zero length input (#31602)
35bee0c729  # separate op for rowwise counter (#31612)
90a187618e  # Integrate masked sparse Adagrad (#31641)
f4e955ff62  # Change PackSegments to ensure consistent behavior between CPU and GPU
b102550d2c  # Allow to pass in masks through db (#31676)
daf00beaba  # Remove duplicated Numa detection code. (#30628)
86a4e2135d  # Do not register `const float *` type on utiliy_ops.cu (#31583)
9407137102  # Update the descriptive error message for enforce fail (#31575)
809ee9d04c  # Enable personalized FC weight_init and sparse_emb weight_init (#31707)
84dfa96f62  # Fix -Wundef warning in conversions.h
8b4feff01d  # Use simd version for fp16 conversions (#31897)
d2fdf140af  # Combine all the user inputs together and convert them to fp16 (#31898)
9e9ca6ec37  # add conversion functions to embedding tables (#31083)
28c1258f18  # Scale init for batch-norm and layer-norm (#31983)
f6f1e0aef5  # Automatic update of fbcode/onnx to 65020daafa9183c769938b4512ce543fd5740f8f (#32125)
879620e85e  # [caffe2] fix how np.clip is used in lengths_reducer_fused_{4,8}_rowwise_ops_test (#32086)
8c3ee9f2ba  # [Python] Deprecate use of scipy.misc.logsumexp and scipy.misc.comb (#32209)
0392e8384b  # Fix simple typo: whos -> whose (#31288)
851a7e861b  # Add CAFFE2_API to video decoding functions (#31187)
d75b6b3f9d  # Support shape inference and lowering of SparseLengthsWeightedSumFused4BitRowwise (#32257)
f94aab45fd  # Logical condition reduction (#32201)
ef5ae4823a  # Register RoIAlignRotated with C10
91bdb872ce  # fix spelling mistake: excpected -> expected
4e69352713  # Add 64bit atomic fetch add (#32354)
df514fd8c0  # C++ C2/Glow operator unittest
9b6ec61bfd  # exposing CPU/GPU Copy ops (#32248)
8c40a78277  # Back out "Calling JITed 8 Bit Fused SLS in FBGEMM from C2" (#32381)
ec4be4e58c  # Redundant condition (#32396)
14e0bec9f2  # [caffe2] remove unnecessary np.set_printoptions and fix test errors (#32475)
685f090ac8  # [Rowwise Pruning][c2 op] Add Quantile Op (#32448)
e735395fc6  # [caffe2] use 2-stage EmbeddingSpMDM interface (#32271)
bd20274e8f  # [caffe2] use JIT'ed fp32 SLS (#32413)
19bb496a0d  # Enable mkldnn on windows (#31355)
64323ae177  # Back out "Use simd version for fp16 conversions" (#32640)
ffdcbadeaa  # Minor refactoring to improve code reuse (#32675)
0327e75e14  # Back out "[caffe2] use JIT'ed fp32 SLS" (#32711)
1f78bd0774  # [caffe2] Early error throwing for currupted embeddings
e84f9d9d0c  # Fix TensorProtosDBInput AttributeError (#32274)
a840afbeb4  # [pytorch][embeddingbag_8bit] Add include_last_offset option to Fused 8bit EmbeddingBag and parallelize the op (#32683)
14c15eb3b0  # Py2 -> py3 for caffe2/caffe2/contrib/tensorboard (#32882)
b4b1b100bd  # Add a loop test for onnxified net (#32935)
18d1896ba0  # Fix confusing "does not have GPU support" warning message (#30721)
e76fa9822d  # [C2] Introduce extra_info force CPU tags for auto-generated iteration counter blobs (#32607)
674dca0831  # Automatic update of fbcode/onnx to 8b3f7e2e7a0f2aba0e629e23d89f07c7fc0e6a5e (#33075)
6f46962f21  # [1/3] Bind IndexHash to PyTorch (#33015)
6c0dc66cb4  # [caffe2] use JIT'ed fp32 SLS (#33123)
9d9fa2eace  # [2/3] Bind Bucketize to PyTorch (#33014)
1767ae8daf  # [caffe2] remove dnnlowp log code (#33184)
16685d93e9  # [TVM] Add ReplaceNaN op (#33256)
b98c7d34ed  # [TVM] Add clip op to c2_frontend (#33257)
acea368095  # Fix compilation error when buildng with FFMPEG (#27589)
e5c7b7b8b5  # Automatic update of fbcode/onnx to 04a29addfd5b912812addb8dea5f8763fbfaad01 (#33328)
92fbf7cf97  # [caffe2] use JIT'ed fp16 SLS (#32432)
ecd3c252b4  # Suport all length one SLS op lowering: C2 part (#33332)
c57f8984e6  # [caffe2] make order btw div and mul in adgrad consistent (#32974)
96e5dea9f4  # Remove unused variable (#33484)
e5a02aa2fe  # [caffe2] simplify relative error expr (#32999)
81394581a3  # [Caffe2][ThreadPool] Make sure numThreads does not exceed the number of big cores (#33523)
e95282ab28  # [caffe2] make fused rowwise quant/dequant op work for N-dim tensors (#33426)
108fc78395  # [caffe2] fix invalid % escape in inline assembly strings (#33554)
23846d5a38  # [caffe2] use Clang identification macro in various places (#33574)
3498c000e2  # [TVM] Remove dynamic batch size dispatching (#33584)
6474ea404d  # [C2] Native GPU implementation for bucketize (#33529)
696527e659  # [caffe2] Add embedding empty ratio checker (disabled by default) (#33145)
65864d3634  # [C2] Small improvement for elementwise_mul operator. (#33537)
4460c8b034  # [C2] Tiny changes to adagrad to make it slightly better. (#33727)
ee23944f46  # [Caffe2] Fix shape inference for element-wise operators (#33431)
04f88a3a7b  # Add partition info message to NetDef (#33616)
a7fe200f5f  # [caffe2] simplify caffe2 code with fbgemm handling block size 1 emb (#33774)
1507573a52  # [caffe2] fix no return statement in constexpr function Clang error in TypeIndex.h (#33576)
5dde8cd483  # [caffe2] fix no matching function min/max Clang errors (#33563)
56d9906083  # update mapping of fake operators (#33946)
4fb8679218  # [caffe2] fix field initialization after base Clang errors (#33556)
4377061baf  # [caffe2] fix atomicAdd redeclaration Clang error (#33559)
0e52627358  # Fixing pthreadpool symbol conflict issue. (#33869)
ad17dafc50  # [caffe2] Remove python2 from operator_test (#33977)
9239608037  # fix windows clang attributes (#33959)
b874c039f6  # Allow checking for cached module before asserting (#33954)
0759191f12  # blacklist spatialBN until bitwise matching (#34092)
8a14b41617  # fix warnings reported by PVS (#33868)
e0b90b87a4  # [C2] Fix slowness of the ReshapeOp. (#33729)
1702152ef9  # fixup unit tests (#34105)
7289e8e865  # [caffe2] std::numeric_limits<double>::quiet_NaN() use instead of ::nan("") (#33566)
9650253d70  # [caffe2] fix ambiguous call to 'fmaxType' THCHalfAutoNumerics.cuh (#33569)
7c20578794  # NNPI op mapping correct SpatialBN NNPI op name (#34176)
2ba74b741e  # Add backward Int8Quantize shape inference (#34152)
790274bff2  # [caffe2] Fix signed unsigned comparison warning (#34161)
8269c4f3d3  # Added nullptr check for pthradpool_get_threads_count (#34087)
75d29f8d3e  # Allow converting IValue to vector<string> (#34269)
879a90b322  # [ModelLoading] Use byte encoding for uint8, fp16 etc. instead of int32 (#34343)
79e1305519  # [net_runner] Get shape info from qtensors (#34321)
259d7299db  # [caffe2] do not declare __assert_fail in clang builds (#33893)
0dc0fffca1  # [net_transform] only skip ConstantFill for autogen_grad (#34628)
fe9b4e3cba  # [DPER3] Blob Reorder (#33579)
721bd11cc3  # [caffe2] Refactor out common util functions from tvm_transformer (#34652)
4ae74b3b25  # [DPER3][Shape Inference] Initial Shape Inference in DPER3 frontend (#33607)
808f84ee35  # [Shape Inference] Update shape inference in dper3 backend - C2 part (#34474)
8f854fb9e2  # [1/n][multi-tower] add partition info in predictor construction (#34175)
1d81bd02cc  # Export roi_align_gradient_op to c10 (#34776)
99b91ee2ad  # [fix][tiny][caffe2] Avoid triggering errors when allow ratio is 100% (#34757)
ef78fa8668  # caffe2::OperatorBase do not need to be aware of at::Tensor functions (#34810)
6d8649dc53  # [caffe2] fix Transpose2D calls in NHWC<->NCHW (#34625)
e70c28856f  # [Caffe2] Move more method implementations from tensor.h to tensor.cc (#34811)
d9b97a4ffd  # [caffe2] open source 2/4-bit SLS operators (#34783)
cfab65d90d  # Fix CMake Dev warning in caffe2/CMakeLists.txt (#34886)
3ad7dfa2cf  # move emulation libraries to contrib (#34861)
959a7138fd  # Support RowWiseSparseAdam on GPU (#34341)
bcbdba450c  # [caffe2] open source 2/4-bit SLS operators (#34903)
a3de359464  # Do not throw from CUDAContext destructor (#34756)
57f29a44c7  # Bug fix of the histogram observers (#30970)
7ad03855dc  # Fix 'template' keyword warning with clang-cl and clang.exe (#32104)
12d5933969  # Bug fix of norm minimization for dev mode (#31462)
e2f1288514  # Add utils to inspect fp16/int8 packed weights (#32979)
c9ed111894  # [caffe2][quantization] Add initializer and precision as read-only property to QueryTensorQparam (#34706)
373c80ee90  # Fix missing header (#34762)
2599b9b551  # Add output_size argument to caffe2 Int8ResizeNearest (#30202)
968c0d4a46  # Add support for converting quantized AvgPool2d and Reshape operations (#30490)
980aead1f8  # Add support for quantized slice conversion (#30498)
a2f3c6c26f  # Call RandomNumberSeed() on-demand (#33539)
